---
title: "TP-Markdown"
output: pdf_document
date: "2024-08-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

Para el trabajo práctico se eligió una base de datos sobre la relación entre la diabetes y las distintas variables. Esta base de datos fue obtenida a través de la página de Kaggle. Cuenta con 16 variables, de las cuales 5 son de tipo métrico y el resto son nominales y alrededor de 100.000 observaciones, por lo cual debimos reducirlo de forma aleatoria y proporcional. Es decir que la mitad de los individuos de las observaciones sufren de diabetes y la otra mitad, no. Luego de realizar esto, quedaron en total 17.000 observaciones (de las cuales 8.500 son diabéticos y el resto no). Se decidió usar este conjunto de datos para árboles de decisión ya que contiene tanto variables métricas cómo nominales, haciendo que los árboles de decisión sean perfectos para el manejo de los datos. No sólo eso, sino que además son fáciles de leer y accesibles. El objetivo es poder predecir a partir de otros datos si el individuo en cuestión sufre de diabetes o no y ver cómo las variables interactúan entre sí.

### Librerías necesarias

```{r}
# Instalar paquetes necesarios si no están descargados todavía
#install.packages(c("rpart", "caret", "pROC", "e1071"))

# Cargar los paquetes
library(rpart)
library(caret)
library(pROC)
library(e1071)
library(ggplot2)
library(corrplot)

```

# Dataset Diabetes

## Se cargan los datos

```{r data}
data_original = read.csv('diabetes_dataset.csv')
```

### Reducción de la cantidad de observaciones

```{r}

data_sin = data_original[data_original$diabetes == 0,]
data_con = data_original[data_original$diabetes == 1,]

cant_diabetes = nrow(data_original[data_original$diabetes > 0, ])

set.seed(40)


if(nrow(data_sin) > cant_diabetes) {
  data_sin <- data_sin[sample(nrow(data_sin), cant_diabetes, replace = FALSE), ]
}

data <- rbind(data_con, data_sin)


```

# 2: Preparación de los datos

### Pre-procesamos las columnas categóricas

```{r}


# Convertir columnas a factores y manejar valores desconocidos

data$gender <- factor(data$gender, levels = c("Male", "Female", "Unknown"))
data$gender[data$gender == "Other"] <- "Unknown"

data$location <- as.factor(data$location)
data$smoking_history <- as.factor(data$smoking_history)

data$diabetes <- as.factor(data$diabetes)

# Se crea una nueva y única columna para la raza


data$race <- apply(data[, c("race.AfricanAmerican", "race.Asian", "race.Caucasian", "race.Hispanic", "race.Other")], 1, function(row) {
  race <- names(which(row == 1))
  if (length(race) == 0) return(NA)
  return(race)
})


```

## Summary

```{r}
summary(data)
```

## Visualizaciones

```{r}
hist(data$age,
     main = "Distribución de Edad",
     xlab = "Edad",
     ylab = "Frecuencia",
     col = "skyblue",       
     border = "white",      
     breaks = 20,          
     las = 1,              
     freq = TRUE)


gender_counts <- table(data$gender)

# Crear un gráfico de barras de la tabla de frecuencias
barplot(gender_counts,
        main = "Distribución por Género",
        xlab = "Género",
        ylab = "Frecuencia",
        col = c("lightblue", "lightgreen"), 
        border = "black",
        las = 1,                             
        cex.names = 0.8,                      
        ylim = c(0, max(gender_counts) * 1.2))


data$race <- apply(data[, c("race.AfricanAmerican", "race.Asian", "race.Caucasian", "race.Hispanic", "race.Other")], 1, function(row) {
  race <- names(which(row == 1))
  if (length(race) == 0) return(NA)  # Manejo de valores NA si ninguna raza está seleccionada
  return(race)
})

ggplot(data, aes(x = race, fill = race)) +
  geom_bar() +
  labs(title = "Distribución de Raza", x = "Raza", y = "Frecuencia") +
  theme_minimal()

# Histograma del IMC

ggplot(data, aes(x = bmi)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
  labs(title = "Distribución del IMC", x = "IMC", y = "Frecuencia") +
  theme_minimal()

# Boxplot de Edad por Género

ggplot(data, aes(x = gender, y = age, fill = gender)) +
  geom_boxplot() +
  labs(title = "Distribución de Edad por Género", x = "Género", y = "Edad") +
  theme_minimal()

# 1. Filtrar solo las columnas numéricas

data$year <- NULL

df_numeric <- data[, sapply(data, is.numeric)]

# 2. Crear la matriz de correlación

cor_matrix <- cor(df_numeric, use = "complete.obs")

# 3. Visualizar la matriz de correlación con corrplot

corrplot(cor_matrix, method = "color", tl.col = "black", tl.cex = 0.8)


```

# Observaciones

Son registros desde 2015 hasta 2022. Tenemos distintas variables desde género, edad, dónde reside, su raza, si sufre de hipertensión, problemas del cardíacos, si es fumador, su IMC, HbA1c (hemoglobina glicosilada), glucosa en sangre y por último si sufre de diabetes o no. De todas las observaciones, hay 9492 mujeres y 7507 hombres. Se pudo observar que las razas y ubicaciones de los individupos a través del conjunto fueron divididas equitativamente. El individuo promedio tiene alrededor de cincuenta años de edad.

En la matriz de correlación se puede observar que los tonos azules más oscuros tienen una correlación positiva (es decir, cerca de 1), mientras que los más rojos una correlación negativa (cerca de -1 ) y por último, los tonos más claros y casi blancos indican una correlación muy débil o casi nula. Algo notable de esta visualización es que se puede observar que para las variables 'bmi' y 'blood_glucose_level' tienen una correlación positiva, lo cual tiene mucho sentido dado el contexto de salud ya que los mayores índices de masa corporal se asocian a mayores niveles de glucosal.

# 3: Construcción árbol básico

Los datos fueron divididos en tres partes (70%, 15% y 15%) de forma aleatoria con una seed para destinar cada una de las partes a diferentes etapas del proceso.

```{r}
set.seed(123)

# Se crean los índices para la partición

indices <- sample(seq_len(nrow(data)), size = 0.7 * nrow(data))
trainData <- data[indices, ]
testData <- data[-indices, ]

# Se repite el paso anterior para los índices de la partición del conjunto de entrenamiento

indices_valid <- sample(seq_len(nrow(trainData)), size = 0.5 * nrow(testData))
validData <- trainData[indices_valid, ]
testData <- trainData[-indices_valid, ]

# Ahora se tiene trainData, validData, y testData

```

## Se crea un árbol de decision a través de "rpart"

```{r}

default_tree <- rpart(diabetes ~ ., data = trainData , method = "class")

```

Los hiperparámetros por default de rpart son:

}

```{r}
rpart.control()

# Resumen del modelo
print(default_tree)
printcp(default_tree)
```

## Visualización del árbol

```{r}
plot(default_tree)
text(default_tree, use.n = TRUE, cex = 0.8)
```
## Explicación de la estructura del árbol
Este árbol comienza por el nodo raíz o padre. El primer corte se realiza en la variable 'blood_glucose_level' con un umbral de 210. Es decir que la primera clasificación de los datos ocurre así:
Si 'blood_glucose_level' < 210, el árbol sigue por el lado izquierdo.
Si 'blood_glucose_level' >= 210, el árbol sigue por el lado derecho.
Luego, el segundo nivel de decisión, del lado izquierdo, se basa en la variable 'hbA1c_level' con un umbral de 5.35
Si 'hbA1c_level < 5.35', indica que no tiene diabetes
Si 'hbA1c_level >= 5.35' sigue con la variable 'age' y un umbral de 43.5
Del lado derecho, el nodo que queda es un nodo terminal. Esto sugiere que hay una clasificación directa.
Por último, al final de todo se encuentran todos los nodos terminales que ya no poseen ninguna otra división sino una clasificación.

# 4. Evaluación del árbol básico

## Predicciones

```{r}
# Clase predicha
predicciones <- predict(default_tree, testData, type = "class")
predicciones <- factor(predicciones)
testData$diabetes <- factor(testData$diabetes)


# Ver las predicciones
#print(predicciones)

```

## Confusion Matrix

La matriz de confusión permite ver el desempeño del algoritmo propuesto.

```{r}

# Se crea una matriz de confusión
conf_matrix <- confusionMatrix(predicciones, testData$diabetes)

# Accuracy
accuracy <- conf_matrix$overall["Accuracy"]
print(conf_matrix)

```
Interpretación de los resultados:
Se puede ver que el modelo predijo correctamente 4140 instancias no tienen la condición 0 (es decir, no son diabéticos) mientras que el número de falsos negativos fue de 373. Para las instancias de verdaderos positivos, acertó 4281 y clasificó erroneamente 556 (falsos positivos).
A partir de estos números anteriores se pudo calcular la Sensitivity y Specificity. Que son las proporciones en las que el modelo predijo bien para verdaderos positivos y verdaderos negativos. Estas fueron de 88.16% y 91.99% respectivamente.
Luego, la Accuracy fue de 0.9006 o 90.06%, pero, ¿qué significa esto? Esto implica que de todas las instancias totales el modelo predijo correctamente 90.06% de ella. Además como las clases están balanceadas, esto refleja que el modelo está haciendo efectivamente su trabajo.


## Precision & Recall

```{r}
precision <- conf_matrix$byClass["Pos Pred Value"]
recall <- conf_matrix$byClass["Sensitivity"]

print(precision)
print(recall)

```
Interpretación:
Una precision de 95.66% fueron aquellas instancias en las que el modelo predijo que eran positivas y realmente lo eran. Mientras que el recall fue de 97.24%.
Un precision y recall alto implica que el modelo predice correctamente la mayoría de los positivos sin perder muchos casos positivos reales.

## f1- Score

```{r}
# F1-score
f1_score <- 2 * (precision * recall) / (precision + recall)
print(f1_score)

```
Interpretación:
Esto refleja que hay un buen balance entre precision y recall. Por consecuencia, el model tiene un buen manejo sobre tanto para falsos positivos como para falsos negativos.

## AUC-ROC: Área bajo la curva ROC.

```{r}


# Probabilidad predicha
predicciones_prob <- predict(default_tree, testData, type = "prob")
probas_positivas = predicciones_prob[,2]
# Calcular el ROC y AUC
roc_curve <- roc(testData$diabetes, probas_positivas, direction = "<")
auc_roc <- auc(roc_curve)

# Mostrar el AUC-ROC
print(auc_roc)

# Graficar la curva ROC
plot(roc_curve, main = "Curva ROC", col = "blue", lwd = 2)

# Agregar la línea diagonal de no discriminación (es decir, el azar)
abline(a = 0, b = 1, lty =2,col="red")
```
Interpretación de la curva: El AUC de 0.9674 muestra que el modelo tiene un buen rendimiento para la clasificación binaria, con alta sensibilidad y especificidad en la mayoría de los umbrales. La curva ROC indica que el modelo discrimina bien entre casos positivos y negativos, superando claramente la línea de no discriminación (AUC = 0.5).


###

# 5. Optimizacion

## Búsqueda de Hiperparámetros

Definimos los candidatos para cada hiperparámetros de los árboles de decision

# Hiperparámetros para árbol de decisión

### 1. 'minSplit'

**Descripción:** Función para medir la cálidad de una división.\
**Candidatos:** - `None` -`10` - `20` - `30` - `50`

### 3. 'minBucket'

**Descripción:** Profundidad máxima del árbol.\
**Candidatos:** - `None` - `5` - `10` - `15` - `20`

### 4. 'maxDepth'

**Descripción:** Número mínimo de muestras requeridas para dividir un nodo.\
**Candidatos:** - `2` - `5` - `10`

### 5. 'maxCompete'

**Descripción:** Número mínimo de muestras requeridas en un nodo hoja.\
**Candidatos:** - `None`- `1` - `3` - `5` - `10`

```{r}



# Se definen los hiperparámetros y sus candidatos

minSplit <- c(10, 20, 30, 50)
minBucket <- c(5, 10, 15, 20)
maxDepth <- c(2, 5, 10, 15, 20, 25)
maxCompete <- c(1, 3, 5, 10)

# Se crea una combinación de todos los hiperparámetros

grid <- expand.grid(
  minsplit = minSplit,
  minbucket = minBucket,
  maxdepth = maxDepth,
  maxcompete = maxCompete
)
# Crear un dataframe para almacenar los resultados de cada combinación
results <- data.frame(
  minsplit = numeric(),
  minbucket = numeric(),
  maxdepth = numeric(),
  maxcompete = numeric(),
  auc = numeric()
)
# Se inicializan variables para almacenar el mejor modelo y su rendimiento

best_auc <- 0
best_model <- NULL
best_params <- list()

# For para probar todas las combinaciones de hiperparámetros
for (i in 1:nrow(grid)) {
  
  # Extraer los hiperparámetros actuales
  params <- grid[i, ]
  
  # Configurar los parámetros de control de rpart
  #cp y xval son 0 para poder construir árboles con la máxima profundidad
  control <- rpart.control(
    cp = 0,                       
    minsplit = params$minsplit,
    minbucket = params$minbucket,
    maxdepth = params$maxdepth,
    xval = 0                      
  )
  
  # Se entrena al modelo usando rpart con los hiperparámetros actuales
  model <- rpart(diabetes ~ ., data = validData, method = "class", control = control)
  
  # Se predecir en el conjunto de validación y calcular AUC-ROC
  valid_pred <- predict(model, newdata = validData, type = "prob")[,2]
  auc_valid <- auc(roc(validData$diabetes, valid_pred))
  
   # Guardar los resultados en el dataframe
  results <- rbind(results, data.frame(
    minsplit = params$minsplit,
    minbucket = params$minbucket,
    maxdepth = params$maxdepth,
    maxcompete = params$maxcompete,
    auc = auc_valid
  ))
  # Actualizar el mejor modelo si el actual es mejor
  if (auc_valid > best_auc) {
    best_auc <- auc_valid
    best_model <- model
    best_params <- params
  }
  
  # Se imprime el progreso
  
  cat("Combination", i, "of", nrow(grid), "- AUC-ROC:", auc_valid, "\n")
}

# La mejor AUC-ROC e hiperparámetros optimizados del modelo son:
cat("Mejor AUC-ROC:", best_auc, "\n")
cat("Mejores Hiperparámeteros:", "\n")
print(best_params)


test_pred <- predict(best_model, newdata = testData, type = "prob")[,2]
auc_test <- auc(roc(testData$diabetes, test_pred))
cat("AUC-ROC on test set:", auc_test, "\n")
print(test_pred)

# Convertir 'predicciones' a factor con los mismos niveles que 'testData$diabetes'
test_pred <- as.factor(test_pred)

##macheamos a factores 
test_pred <- factor(test_pred, levels = levels(testData$diabetes))


# Crear una tabla de confusión
conf_matrix <- confusionMatrix(test_pred, testData$diabetes)

# Accuracy
accuracy <- conf_matrix$overall["Accuracy"]
print(conf_matrix)
```

```{r visualization, echo=TRUE, message=FALSE, warning=FALSE}
library(ggplot2)

# Gráfico de calor para visualizar la relación entre maxdepth y minsplit con AUC-ROC
ggplot(results, aes(x = factor(maxdepth), y = factor(minsplit), fill = auc)) +
  geom_tile() +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(title = "Relación entre Maxdepth, Minsplit y AUC-ROC",
       x = "Maxdepth",
       y = "Minsplit") +
  theme_minimal()

# Gráfico de calor para visualizar la relación entre maxcompete y maxdepth con AUC-ROC
ggplot(results, aes(x = factor(maxcompete), y = factor(maxdepth), fill = auc)) +
  geom_tile() +
  scale_fill_gradient(low = "yellow", high = "purple") +
  labs(title = "Relación entre Maxcompete, Maxdepth y AUC-ROC",
       x = "Maxcompete",
       y = "Maxdepth") +
  theme_minimal()

# Gráfico de líneas para observar cómo varía el AUC-ROC con diferentes combinaciones de hiperparámetros
ggplot(results, aes(x = maxdepth, y = auc, color = factor(minsplit))) +
  geom_line() +
  geom_point() +
  labs(title = "AUC-ROC vs Maxdepth para diferentes Minsplit",
       x = "Maxdepth",
       y = "AUC-ROC",
       color = "Minsplit") +
  theme_minimal()
```



```{r}

valid_pred <- predict(best_model, newdata = validData, type = "prob")[,2]
roc_test <- roc(validData$diabetes, valid_pred)
auc_test <- auc(roc_test)
cat("AUC-ROC on test set:", auc_test, "\n")
print(test_pred)

## Visualización de la curva AUC-ROC

# Se grafica la curva ROC
plot(roc_test, col = "blue", lwd = 2, main = "Curva AUC-ROC", auc.polygon = TRUE, grid = TRUE) 

# Se añade la línea diagonal 
abline(a = 0, b = 1, col = "gray", lty = 2)

# Convertir 'predicciones' a factor con los mismos niveles que 'testData$diabetes'
valid_pred <- as.factor(valid_pred)

##macheamos a factores 
valid_pred <- factor(valid_pred, levels = levels(validData$diabetes))

# Crear una tabla de confusión
conf_matrix <- confusionMatrix(valid_pred, validData$diabetes)

# Accuracy
accuracy <- conf_matrix$overall["Accuracy"]
print(conf_matrix)
```

# 6. Interpretación de los resultados

A la hora de comparar ambas curvas, se puede observar que en esta segunda curva (que contiene lo hiperparámetros optimizados), que se acerca mucho más al vértice de la izquierda. Esto podría indicar robustez, es decir, que no es tan sensible a cambios en los datos de entrada. 
Otra diferencia es que podemos ver que el área debajo de la curva en la segunda curva es muy cercano a 1, lo cual señala un muy buen rendimiento mientras que en la primera se nota que es un poco más pequeña.
Además, otra diferencia importante es que en la curva del modelo optimizado se puede abstraer que este puede realizar mejores distinciones entre clases positivas y negativas, con muy pocos falsos negativos y falsos positivos.



#7 

```{r generar-datasets-na, echo=TRUE, message=FALSE, warning=FALSE}
set.seed(123)  # Fijar semilla para reproducibilidad

# Función para agregar NAs aleatoriamente
add_na_randomly <- function(data, na_fraction) {
  data_with_na <- data
  for (col in names(data_with_na)) {
    if (is.numeric(data_with_na[[col]])) {
      na_indices <- sample(seq_len(nrow(data_with_na)), size = floor(na_fraction * nrow(data_with_na)))
      data_with_na[na_indices, col] <- NA
    }
  }
  return(data_with_na)
}

# Crear tres versiones de los conjuntos de datos con diferentes porcentajes de NAs
trainData_20na <- add_na_randomly(trainData, 0.2)
validData_20na <- add_na_randomly(validData, 0.2)
testData_20na <- add_na_randomly(testData, 0.2)

trainData_50na <- add_na_randomly(trainData, 0.5)
validData_50na <- add_na_randomly(validData, 0.5)
testData_50na <- add_na_randomly(testData, 0.5)

trainData_75na <- add_na_randomly(trainData, 0.75)
validData_75na <- add_na_randomly(validData, 0.75)
testData_75na <- add_na_randomly(testData, 0.75)

# Verificar algunos ejemplos de los conjuntos de datos
summary(trainData_20na)
summary(trainData_50na)
summary(trainData_75na)

```

```{r entrenar-modelos-na, echo=TRUE, message=FALSE, warning=FALSE}
# Inicializar variables para almacenar resultados
results_na <- data.frame(
  dataset = character(),
  na_fraction = numeric(),
  best_auc = numeric(),
  auc_test = numeric(),
  stringsAsFactors = FALSE
)

# Lista de datasets para iterar
datasets <- list(
  list(name = "20% NAs", train = trainData_20na, valid = validData_20na, test = testData_20na, na_fraction = 0.2),
  list(name = "50% NAs", train = trainData_50na, valid = validData_50na, test = testData_50na, na_fraction = 0.5),
  list(name = "75% NAs", train = trainData_75na, valid = validData_75na, test = testData_75na, na_fraction = 0.75)
)

# Entrenamiento de modelos para cada conjunto de datos con valores faltantes
for (ds in datasets) {
  best_auc_na <- 0
  best_model_na <- NULL
  
  # Entrenamiento de modelos con las combinaciones de hiperparámetros optimizadas
  for (i in 1:nrow(grid)) {
    params <- grid[i, ]
    
    control <- rpart.control(
      cp = 0,
      minsplit = params$minsplit,
      minbucket = params$minbucket,
      maxdepth = params$maxdepth,
      xval = 0
    )
    
    model_na <- rpart(diabetes ~ ., data = ds$train, method = "class", control = control)
    
    # Predecir en el conjunto de validación y calcular AUC-ROC
    valid_pred_na <- predict(model_na, newdata = ds$valid, type = "prob")[,2]
    auc_valid_na <- auc(roc(ds$valid$diabetes, valid_pred_na))
    
    if (auc_valid_na > best_auc_na) {
      best_auc_na <- auc_valid_na
      best_model_na <- model_na
    }
  }
  
  # Evaluar el modelo optimizado en el conjunto de prueba
  test_pred_na <- predict(best_model_na, newdata = ds$test, type = "prob")[,2]
  auc_test_na <- auc(roc(ds$test$diabetes, test_pred_na))
  
  # Guardar los resultados
  results_na <- rbind(results_na, data.frame(
    dataset = ds$name,
    na_fraction = ds$na_fraction,
    best_auc = best_auc_na,
    auc_test = auc_test_na
  ))
  
  # Imprimir resultados
  cat("Dataset:", ds$name, "- Mejor AUC-ROC en validación:", best_auc_na, "- AUC-ROC en prueba:", auc_test_na, "\n")
}
```

```{r visualizacion-na, echo=TRUE, message=FALSE, warning=FALSE}
# Visualización de cómo cambia el AUC-ROC con diferentes proporciones de NAs
ggplot(results_na, aes(x = factor(na_fraction), y = auc_test, fill = factor(na_fraction))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "AUC-ROC en Conjunto de Prueba con Diferentes Proporciones de NAs",
       x = "Proporción de NAs",
       y = "AUC-ROC en Prueba") +
  theme_minimal()
```


Generación de Conjuntos de Datos con NAs:

Usamos la función add_na_randomly para agregar valores faltantes (NA) aleatoriamente en las variables predictoras de los conjuntos de datos de entrenamiento, validación y prueba.
Generamos tres conjuntos de datos con diferentes porcentajes de NAs: 20%, 50%, y 75%.
Entrenamiento de Modelos Optimizados:

Iteramos sobre cada conjunto de datos con diferentes proporciones de NAs.
Entrenamos un modelo de árbol de decisión utilizando los mismos hiperparámetros optimizados que en el punto 5.
Calculamos el AUC-ROC para cada modelo entrenado en el conjunto de validación y seleccionamos el mejor modelo.
Visualización del Rendimiento:

Usamos ggplot2 para crear un gráfico de barras que muestra cómo varía el AUC-ROC en el conjunto de prueba a medida que aumenta la proporción de valores faltantes.
Este gráfico ayudará a analizar cómo los valores faltantes afectan el rendimiento del modelo.