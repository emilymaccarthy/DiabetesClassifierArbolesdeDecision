---
title: "TP-Markdown"
output: pdf_document
date: "2024-08-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

Para el trabajo práctico se eligió una base de datos sobre la relación entre la diabetes y las distintas variables. Esta base de datos fue obtenida a través de la página de Kaggle. Cuenta con 16 variables, de las cuales 5 son de tipo métrico y el resto son nominales y alrededor de 100.000 observaciones, por lo cual debimos reducirlo de forma aleatoria y proporcional. Es decir que la mitad de los individuos de las observaciones sufren de diabetes y la otra mitad, no. Luego de realizar esto, quedaron en total 17.000 observaciones (de las cuales 8.500 son diabéticos y el resto no). Se decidió usar este conjunto de datos para árboles de decisión ya que contiene tanto variables métricas cómo nominales, haciendo que los árboles de decisión sean perfectos para el manejo de los datos. No sólo eso, sino que además son fáciles de leer y accesibles. El objetivo es poder predecir a partir de otros datos si el individuo en cuestión sufre de diabetes o no y ver cómo las variables interactúan entre sí.

### Librerías necesarias

```{r}
# Instalar paquetes necesarios si no están descargados todavía
#install.packages(c("rpart", "caret", "pROC", "e1071"))

# Cargar los paquetes
library(rpart)
library(caret)
library(pROC)
library(e1071)
library(ggplot2)
library(corrplot)

```

# Dataset Diabetes

## Se cargan los datos

```{r data}
data_original = read.csv('diabetes_dataset.csv')
```

### Reducción de la cantidad de observaciones

```{r}

#Separamos los datos entre los pacientes con diabete y sin diabetes
data_sin = data_original[data_original$diabetes == 0,]
data_con = data_original[data_original$diabetes == 1,]

#contamos la cantidad de pacientes con diabetes 
cant_diabetes = nrow(data_original[data_original$diabetes > 0, ])

# Sabemos que la cantidad de gente con diabetes es menor a la cantidad sin diabetes en el dataset, balanceamos esto y hacemos que seaa 50/50 la cantidad de casos con diabetes y sin diabetes (ponemos el seed para reproducibilidad )
set.seed(40)
if(nrow(data_sin) > cant_diabetes) {
  data_sin <- data_sin[sample(nrow(data_sin), cant_diabetes, replace = FALSE), ]
}

#juntamos la data y al guardamos
data <- rbind(data_con, data_sin)



```

# 2. Preparación de los datos

### Pre-procesamos las columnas categóricas

```{r}
# Borramos "loation"
data_sin_location <- subset(data, select = -location)

# Convertir columnas a factores y manejar valores desconocidos

data$gender <- factor(data$gender, levels = c("Male", "Female", "Unknown"))
data$gender[data$gender == "Other"] <- "Unknown"

data$location <- as.factor(data$location)

#data$smoking_history <- as.factor(data$smoking_history)

data$diabetes <- as.factor(data$diabetes)

# Se crea una nueva y única columna para la raza


data$race <- apply(data[, c("race.AfricanAmerican", "race.Asian", "race.Caucasian", "race.Hispanic", "race.Other")], 1, function(row) {
  race <- names(which(row == 1))
  if (length(race) == 0) return(NA)
  return(race)
})


```

## Summary

```{r}
summary(data)
```

## Visualizaciones

```{r}
hist(data$age,
     main = "Distribución de Edad",
     xlab = "Edad",
     ylab = "Frecuencia",
     col = "skyblue",       
     border = "white",      
     breaks = 20,          
     las = 1,              
     freq = TRUE)


gender_counts <- table(data$gender)

# Crear un gráfico de barras de la tabla de frecuencias
barplot(gender_counts,
        main = "Distribución por Género",
        xlab = "Género",
        ylab = "Frecuencia",
        col = c("lightblue", "lightgreen"), 
        border = "black",
        las = 1,                             
        cex.names = 0.8,                      
        ylim = c(0, max(gender_counts) * 1.2))


data$race <- apply(data[, c("race.AfricanAmerican", "race.Asian", "race.Caucasian", "race.Hispanic", "race.Other")], 1, function(row) {
  race <- names(which(row == 1))
  if (length(race) == 0) return(NA)  # Manejo de valores NA si ninguna raza está seleccionada
  return(race)
})

ggplot(data, aes(x = race, fill = race)) +
  geom_bar() +
  labs(title = "Distribución de Raza", x = "Raza", y = "Frecuencia") +
  theme_minimal()

# Histograma del IMC

ggplot(data, aes(x = bmi)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
  labs(title = "Distribución del IMC", x = "IMC", y = "Frecuencia") +
  theme_minimal()

# Boxplot de Edad por Género

ggplot(data, aes(x = gender, y = age, fill = gender)) +
  geom_boxplot() +
  labs(title = "Distribución de Edad por Género", x = "Género", y = "Edad") +
  theme_minimal()

# 1. Filtrar solo las columnas numéricas

data$year <- NULL

df_numeric <- data[, sapply(data, is.numeric)]

# 2. Crear la matriz de correlación

cor_matrix <- cor(df_numeric, use = "complete.obs")

# 3. Visualizar la matriz de correlación con corrplot

corrplot(cor_matrix, method = "color", tl.col = "black", tl.cex = 0.8)


```

# Observaciones

Son registros desde 2015 hasta 2022. Tenemos distintas variables desde género, edad, dónde reside, su raza, si sufre de hipertensión, problemas del cardíacos, si es fumador, su IMC, HbA1c (hemoglobina glicosilada), glucosa en sangre y por último si sufre de diabetes o no. De todas las observaciones, hay 9492 mujeres y 7507 hombres. Se pudo observar que las razas y ubicaciones de los individupos a través del conjunto fueron divididas equitativamente. El individuo promedio tiene alrededor de cincuenta años de edad.

En la matriz de correlación se puede observar que los tonos azules más oscuros tienen una correlación positiva (es decir, cerca de 1), mientras que los más rojos una correlación negativa (cerca de -1 ) y por último, los tonos más claros y casi blancos indican una correlación muy débil o casi nula. Algo notable de esta visualización es que se puede observar que para las variables 'bmi' y 'blood_glucose_level' tienen una correlación positiva, lo cual tiene mucho sentido dado el contexto de salud ya que los mayores índices de masa corporal se asocian a mayores niveles de glucosal.

# 3: Construcción árbol básico

Los datos fueron divididos en tres partes (70%, 15% y 15%) de forma aleatoria con una seed para destinar cada una de las partes a diferentes etapas del proceso.

```{r}
split_dataset <- function(dataset, train_size = 0.7, validation_size = 0.15, test_size = 0.15, seed = 123) {
  # Verificar que los tamaños sumen 1
  if (train_size + validation_size + test_size != 1) {
    stop("Los tamaños de train, validation y test deben sumar 1")
  }
  
  # Configurar la semilla para reproducibilidad, si se proporciona
  if (!is.null(seed)) {
    set.seed(seed)
  }
  
  # Número total de filas en el dataset
  num_rows <- nrow(dataset)
  
  # Barajar las filas del dataset
  shuffled_indices <- sample(1:num_rows)
  
  # Calcular los tamaños de los conjuntos
  train_index <- 1:round(train_size * num_rows)
  validation_index <- (length(train_index) + 1):(length(train_index) + round(validation_size * num_rows))
  test_index <- (length(validation_index) + length(train_index) + 1):num_rows
  
  # Dividir el dataset en tres subconjuntos
  train_set <- dataset[shuffled_indices[train_index], ]
  validation_set <- dataset[shuffled_indices[validation_index], ]
  test_set <- dataset[shuffled_indices[test_index], ]

  # Devolver los subconjuntos en una lista
  return(list(train = train_set, validation = validation_set, test = test_set))
}

set = split_dataset(data)


trainData = set$train
validData = set$validation
testData = set$test

```



## Se crea un árbol de decision a través de "rpart"

```{r}

default_tree <- rpart(diabetes ~ ., data = trainData , method = "class")

```

Los hiperparámetros por default de rpart son:

```{r}
rpart.control()

# Resumen del modelo
print(default_tree)
printcp(default_tree)
```

## Visualización del árbol

```{r}
plot(default_tree)
text(default_tree, use.n = TRUE, cex = 0.8)
```
## Explicación de la estructura del árbol
Este árbol comienza por el nodo raíz o padre. El primer corte se realiza en la variable 'blood_glucose_level' con un umbral de 210. Es decir que la primera clasificación de los datos ocurre así:
Si 'blood_glucose_level' < 210, el árbol sigue por el lado izquierdo.
Si 'blood_glucose_level' >= 210, el árbol sigue por el lado derecho.
Luego, el segundo nivel de decisión, del lado izquierdo, se basa en la variable 'hbA1c_level' con un umbral de 5.35
Si 'hbA1c_level < 5.35', indica que no tiene diabetes
Si 'hbA1c_level >= 5.35' sigue con la variable 'age' y un umbral de 43.5
Del lado derecho, el nodo que queda es un nodo terminal. Esto sugiere que hay una clasificación directa.
Por último, al final de todo se encuentran todos los nodos terminales que ya no poseen ninguna otra división sino una clasificación.

# 4. Evaluación del árbol básico

## Predicciones

```{r}
# Clase predicha
predicciones <- predict(default_tree, testData, type = "class")
predicciones <- factor(predicciones)
testData$diabetes <- factor(testData$diabetes)


# Ver las predicciones
#print(predicciones)

```

## Confusion Matrix

La matriz de confusión permite ver el desempeño del algoritmo propuesto.

```{r}

# Se crea una matriz de confusión
conf_matrix <- confusionMatrix(predicciones, testData$diabetes)

# Accuracy
accuracy <- conf_matrix$overall["Accuracy"]
print(conf_matrix)

```
Interpretación de los resultados:
Se puede ver que el modelo predijo correctamente 4140 instancias no tienen la condición 0 (es decir, no son diabéticos) mientras que el número de falsos negativos fue de 373. Para las instancias de verdaderos positivos, acertó 4281 y clasificó erroneamente 556 (falsos positivos).
A partir de estos números anteriores se pudo calcular la Sensitivity y Specificity. Que son las proporciones en las que el modelo predijo bien para verdaderos positivos y verdaderos negativos. Estas fueron de 88.16% y 91.99% respectivamente.
Luego, la Accuracy fue de 0.9006 o 90.06%, pero, ¿qué significa esto? Esto implica que de todas las instancias totales el modelo predijo correctamente 90.06% de ella. Además como las clases están balanceadas, esto refleja que el modelo está haciendo efectivamente su trabajo.


## Precision & Recall

```{r}
precision <- conf_matrix$byClass["Pos Pred Value"]
recall <- conf_matrix$byClass["Sensitivity"]

print(precision)
print(recall)

```
Interpretación:
Una precision de 95.66% fueron aquellas instancias en las que el modelo predijo que eran positivas y realmente lo eran. Mientras que el recall fue de 97.24%.
Un precision y recall alto implica que el modelo predice correctamente la mayoría de los positivos sin perder muchos casos positivos reales.

## f1- Score

```{r}
# F1-score
f1_score <- 2 * (precision * recall) / (precision + recall)
print(f1_score)

```
Interpretación:
Esto refleja que hay un buen balance entre precision y recall. Por consecuencia, el model tiene un buen manejo sobre tanto para falsos positivos como para falsos negativos.

## AUC-ROC: Área bajo la curva ROC.

```{r}


# Probabilidad predicha
predicciones_prob <- predict(default_tree, testData, type = "prob")
probas_positivas = predicciones_prob[,2]
# Calcular el ROC y AUC
roc_curve <- roc(testData$diabetes, probas_positivas, direction = "<")
auc_roc <- auc(roc_curve)

# Mostrar el AUC-ROC
print(auc_roc)

# Graficar la curva ROC
plot(roc_curve, main = "Curva ROC", col = "blue", lwd = 2)

# Agregar la línea diagonal de no discriminación (es decir, el azar)
abline(a = 0, b = 1, lty =2,col="red")
```
Interpretación de la curva: El AUC de 0.9674 muestra que el modelo tiene un buen rendimiento para la clasificación binaria, con alta sensibilidad y especificidad en la mayoría de los umbrales. La curva ROC indica que el modelo discrimina bien entre casos positivos y negativos, superando claramente la línea de no discriminación (AUC = 0.5).


###

# 5. Optimizacion

## Búsqueda de Hiperparámetros

Definimos los candidatos para cada hiperparámetros de los árboles de decision

# Hiperparámetros para árbol de decisión

### 1. 'minSplit'

**Descripción:** Indica el numero minimo de datos que se requieren para dividir un nodo.\
**Candidatos:** - `10` - `20` - `30` - `50`

### 3. 'minBucket'

**Descripción:** Es el mínimo número de observaciones en un nodo terminal u hoja.\
**Candidatos:** - `5` - `10` - `15` - `20`

### 4. 'maxDepth'

**Descripción:** Se encarga de establecer la máxima profundidad del árbol.\
**Candidatos:** - `2` - `5` - `10`

### 5. 'maxCompete'

**Descripción:** Controla el número alternativo de divisiones.\
**Candidatos:** - `1` - `3` - `5` - `10`

```{r}
#f(dataset) -> busque hiperparametris -> entrene el arbol -> prediga, los hacemos para los 3 y comparamos
#
#f(dataset) -> los mejores hyperparametros
#f(arbol,los hyper) -> confMatrix
#


# Se definen los hiperparámetros y sus candidatos

minSplit <- c(10, 20, 30, 50)
minBucket <- c(5, 10, 15, 20)
maxDepth <- c(2, 5, 10, 15, 20, 25)
maxCompete <- c(1, 3, 5, 10)

# Se crea una combinación de todos los hiperparámetros

grid <- expand.grid(
  minsplit = minSplit,
  minbucket = minBucket,
  maxdepth = maxDepth,
  maxcompete = maxCompete
)
# Crear un dataframe para almacenar los resultados de cada combinación
results <- data.frame(
  minsplit = numeric(),
  minbucket = numeric(),
  maxdepth = numeric(),
  maxcompete = numeric(),
  auc = numeric()
)
# Se inicializan variables para almacenar el mejor modelo y su rendimiento

best_auc <- 0
best_model <- NULL
best_params <- list()

# For para probar todas las combinaciones de hiperparámetros
for (i in 1:nrow(grid)) {
  
  # Extraer los hiperparámetros actuales
  params <- grid[i, ]
  
  # Configurar los parámetros de control de rpart
  #cp y xval son 0 para poder construir árboles con la máxima profundidad
  control <- rpart.control(
    cp = 0,                       
    minsplit = params$minsplit,
    minbucket = params$minbucket,
    maxdepth = params$maxdepth,
    xval = 0                      
  )
  
  # Se entrena al modelo usando rpart con los hiperparámetros actuales
  model <- rpart(diabetes ~ ., data = validData, method = "class", control = control)
  
  # Se predecir en el conjunto de validación y calcular AUC-ROC
  valid_pred <- predict(model, newdata = validData, type = "prob")[,2]
  auc_valid <- auc(roc(validData$diabetes, valid_pred))
  
   # Guardar los resultados en el dataframe
  results <- rbind(results, data.frame(
    minsplit = params$minsplit,
    minbucket = params$minbucket,
    maxdepth = params$maxdepth,
    maxcompete = params$maxcompete,
    auc = auc_valid
  ))
  # Actualizar el mejor modelo si el actual es mejor
  if (auc_valid > best_auc) {
    best_auc <- auc_valid
    best_model <- model
    best_params <- params
  }
  
  # Se imprime el progreso
  
  cat("Combination", i, "of", nrow(grid), "- AUC-ROC:", auc_valid, "\n")
}

# La mejor AUC-ROC e hiperparámetros optimizados del modelo son:
cat("Mejor AUC-ROC:", best_auc, "\n")
cat("Mejores Hiperparámeteros:", "\n")
print(best_params)
```

## Visualizamos los resultados del GridSearch

```{r}

# Gráfico de calor para visualizar la relación entre maxdepth y minsplit con AUC-ROC
ggplot(results, aes(x = factor(maxdepth), y = factor(minsplit), fill = auc)) +
  geom_tile() +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(title = "Relación entre Maxdepth, Minsplit y AUC-ROC",
       x = "Maxdepth",
       y = "Minsplit") +
  theme_minimal()

# Gráfico de calor para visualizar la relación entre maxcompete y maxdepth con AUC-ROC
ggplot(results, aes(x = factor(maxcompete), y = factor(maxdepth), fill = auc)) +
  geom_tile() +
  scale_fill_gradient(low = "yellow", high = "purple") +
  labs(title = "Relación entre Maxcompete, Maxdepth y AUC-ROC",
       x = "Maxcompete",
       y = "Maxdepth") +
  theme_minimal()

# Gráfico de líneas para observar cómo varía el AUC-ROC con diferentes combinaciones de hiperparámetros
ggplot(results, aes(x = maxdepth, y = auc, color = factor(minsplit))) +
  geom_line() +
  geom_point() +
  labs(title = "AUC-ROC vs Maxdepth para diferentes Minsplit",
       x = "Maxdepth",
       y = "AUC-ROC",
       color = "Minsplit") +
  theme_minimal()
```


## Testeamos el rendimiento del mejor modelo con los datos de Validacion

```{r}

valid_pred <- predict(best_model, newdata = validData, type = "prob")[,2]
roc_test <- roc(validData$diabetes, valid_pred)
auc_test <- auc(roc_test)
cat("AUC-ROC on test set:", auc_test, "\n")
print(test_pred)

## Visualización de la curva AUC-ROC

# Se grafica la curva ROC
plot(roc_test, col = "blue", lwd = 2, main = "Curva AUC-ROC", auc.polygon = TRUE, grid = TRUE) 

# Se añade la línea diagonal 
abline(a = 0, b = 1, col = "gray", lty = 2)

# Se convierte 'predicciones' a factor con los mismos niveles que 'testData$diabetes'
valid_pred <- as.factor(valid_pred)

## Se matchea a nivel factores 
valid_pred <- factor(valid_pred, levels = levels(validData$diabetes))

# Se crea una tabla de confusión
conf_matrix <- confusionMatrix(valid_pred, validData$diabetes)

# Se calcula la accuracy
accuracy <- conf_matrix$overall["Accuracy"]
print(conf_matrix)
```

## Medición del Auc-Roc con los datos de testeo

```{r}

test_pred <- predict(best_model, newdata = testData, type = "prob")[,2]
auc_test <- auc(roc(testData$diabetes, test_pred))
cat("AUC-ROC on test set:", auc_test, "\n")
print(test_pred)

# Se convierte 'predicciones' a factor con los mismos niveles que 'testData$diabetes'
test_pred <- as.factor(test_pred)

## Se matchea a nivel factor 
test_pred <- factor(test_pred, levels = levels(testData$diabetes))


# Se crea una matriz de confusión
conf_matrix <- confusionMatrix(test_pred, testData$diabetes)

# Se calcula la accuracy
accuracy <- conf_matrix$overall["Accuracy"]
print(conf_matrix)
```
## Interpretación:
En comparación a los resultados de la matriz de confusión anterior, se puede notar que ha habido una mejora notable entre ambos modelos. La accuracy ha aumentado a un 100%, esto significa que el modelo predice bien en todas las instancias. 
También la sensitivity paso a ser 1, esto implica que el modelo identifica todas las instancias positivas de forma correcta sin ningún falso negativo. La specificity ahora también es 1, lo que demuestra que el modelo reconoce todas las instancias 
negativas sin ningún falso positivo.


# 6. Interpretación de los resultados

A la hora de comparar ambas curvas, se puede observar que en esta segunda curva (que contiene lo hiperparámetros optimizados), que se acerca mucho más al vértice de la izquierda. Esto podría indicar robustez, es decir, que no es tan sensible a cambios en los datos de entrada. 
Otra diferencia es que podemos ver que el área debajo de la curva en la segunda curva es muy cercano a 1, lo cual señala un muy buen rendimiento mientras que en la primera se nota que es un poco más pequeña.
Además, otra diferencia importante es que en la curva del modelo optimizado se puede abstraer que este puede realizar mejores distinciones entre clases positivas y negativas, con muy pocos falsos negativos y falsos positivos.

## visualizamos el Arbol
```{r}
install.packages("rpart")
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)

#cex controla el tamaño del texto en el gráfico.
#tweak ajusta el tamaño de la gráfica en general.

rpart.plot(model, type = 3, extra = 104, fallen.leaves = TRUE, cex = 0.8, tweak = 1.2)


```

# 7 Analisis del impacto de valores faltantes (20% 50% 70%) 

```{r}
# Funcion que introduce NA 
dataset_NAgenerator <- function(dataset, rate) {
  # Verificar que el rate esté entre 1 y 100
  if (rate < 1 | rate > 100) {
    stop("El 'rate' debe estar entre 1 y 100")
  }
  
  # Hacer una copia del dataset para no modificar el original
  dataset_na <- dataset
  
  # Convertir el rate a un porcentaje
  rate <- rate / 100
  
  # Número de filas en el dataset
  num_rows <- nrow(dataset_na)
  
  # Número de filas a reemplazar por NA para la columna actual
    num_na <- round(num_rows * rate)
  
  # Iterar sobre cada columna
  for (col in colnames(dataset_na)) {
    # Saltar la columna 'diabetes'
    if (col != 'diabetes') {
      # Seleccionar filas aleatorias para reemplazar por NA en la columna actual
      rows_to_na <- sample(1:num_rows, num_na)
      
      # Reemplazar las filas seleccionadas por NA en la columna actual
      dataset_na[rows_to_na, col] <- NA
    }
    
    
  }
  
  return(dataset_na)
}
```

## Generamos los 3 conjuntos de datos

```{r}
set_20 = split_dataset(data)
train_20 = set_20$train
train_20 = dataset_NAgenerator(train_20,20)
validation_20 = set_20$validation
validation_20 = dataset_NAgenerator(validation_20,20)
test_20 = set_20$test
test_20 = dataset_NAgenerator(test_20,20)

set_50 = split_dataset(data)
train_50 = set_50$train
train_50 = dataset_NAgenerator(train_50,50)
validation_50 = set_50$validation
validation_50 = dataset_NAgenerator(validation_50,50)
test_50 = set_50$test
test_50 = dataset_NAgenerator(test_50,50)

set_70 = split_dataset(data)
train_70 = set_70$train
train_70 = dataset_NAgenerator(train_70,70)
validation_70 = set_70$validation
validation_70 = dataset_NAgenerator(validation_70,70)
test_70 = set_70$test
test_70 = dataset_NAgenerator(test_70,70)


```
## Entrenamos y probamos con los 3 datasets

```{r visualizacion-na, echo=TRUE, message=FALSE, warning=FALSE}
# Visualización de cómo cambia el AUC-ROC con diferentes proporciones de NAs
ggplot(results_na, aes(x = factor(na_fraction), y = auc_test, fill = factor(na_fraction))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "AUC-ROC en Conjunto de Prueba con Diferentes Proporciones de NAs",
       x = "Proporción de NAs",
       y = "AUC-ROC en Prueba") +
  theme_minimal()
```

# 8