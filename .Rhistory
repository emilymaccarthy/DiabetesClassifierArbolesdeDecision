Sensitivity = c(0.9557, 0.9359, 0.8953, 0.7954),
Specificity = c(0.9702, 0.9473, 0.9365, 0.9286),
Kappa = c(0.9265, 0.8835, 0.8339, 0.7285)
)
print(df_metricas)
# Cargar librería ggplot2
#library(ggplot2)
#library(reshape2)
# Convertir el dataframe a formato largo para ggplot2
df_metricas_largo <- melt(df_metricas, id.vars = "Porcentaje_Faltantes")
# Cargar librería ggplot2
#library(ggplot2)
library(reshape2)
# Convertir el dataframe a formato largo para ggplot2
df_metricas_largo <- melt(df_metricas, id.vars = "Porcentaje_Faltantes")
# Gráfico de barras
ggplot(df_metricas_largo, aes(x = Porcentaje_Faltantes, y = value, fill = variable)) +
geom_bar(stat = "identity", position = position_dodge()) +
labs(title = "Comparación de Métricas de Evaluación según el Porcentaje de Datos Faltantes",
x = "Porcentaje de Datos Faltantes",
y = "Valor de la Métrica",
fill = "Métrica") +
theme_minimal()
# Gráfico de líneas
ggplot(df_metricas_largo, aes(x = Porcentaje_Faltantes, y = value, color = variable, group = variable)) +
geom_line(size = 1) +
geom_point(size = 3) +
labs(title = "Tendencia de las Métricas de Evaluación según el Porcentaje de Datos Faltantes",
x = "Porcentaje de Datos Faltantes",
y = "Valor de la Métrica",
color = "Métrica") +
theme_minimal()
#Esto es todo lo que deberiamos hacer oara cad auno de los data sets
test_dataset = function(train,valid,test,grid,porcentaje){
modelo_optimizado = optimizacion(train, grid)
best_auc = modelo_optimizado$AUC
best_model = modelo_optimizado$model
best_params = modelo_optimizado$hyperParameters
results = modelo_optimizado$allResults
#Validacion
rendimiento_validacion = rendimiento_modelo(valid,best_model,paste("Validacion",porcentaje))
matriz_confusion_validacion = rendimiento_validacion$matConfusion
#print(matriz_confusion_validacion)
#Testeo
rendimiento_testeo = rendimiento_modelo(test,best_model, "Testeo",porcentaje)
matriz_confusion_testeo = rendimiento_testeo$matConfusion
#print(matriz_confusion_testeo)
return (list(matConfValid = matriz_confusion_validacion,matConfTest = matriz_confusion_testeo))
}
matrices_data20 = test_dataset(train_20,validation_20,test_20,grid," 20% NA")
#Esto es todo lo que deberiamos hacer oara cad auno de los data sets
test_dataset = function(train,valid,test,grid,porcentaje){
modelo_optimizado = optimizacion(train, grid)
best_auc = modelo_optimizado$AUC
best_model = modelo_optimizado$model
best_params = modelo_optimizado$hyperParameters
results = modelo_optimizado$allResults
#Validacion
rendimiento_validacion = rendimiento_modelo(valid,best_model,paste("- Validación (NAs ", porcentaje, "%)"))
#Esto es todo lo que deberiamos hacer oara cad auno de los data sets
test_dataset = function(train,valid,test,grid,porcentaje){
modelo_optimizado = optimizacion(train, grid)
best_auc = modelo_optimizado$AUC
best_model = modelo_optimizado$model
best_params = modelo_optimizado$hyperParameters
results = modelo_optimizado$allResults
#Validacion
rendimiento_validacion = rendimiento_modelo(valid,best_model,paste("- Validación (NAs ", porcentaje,"%)"))
matriz_confusion_validacion = rendimiento_validacion$matConfusion
#print(matriz_confusion_validacion) paste("- Validación (NAs ", porcentaje,"%)")
#Testeo
rendimiento_testeo = rendimiento_modelo(test,best_model, paste("- Test (NAs ", porcentaje,"%)"))
matriz_confusion_testeo = rendimiento_testeo$matConfusion
#print(matriz_confusion_testeo)
return (list(matConfValid = matriz_confusion_validacion,matConfTest = matriz_confusion_testeo))
}
matrices_data20 = test_dataset(train_20,validation_20,test_20,grid," 20")
print(matrices_data20$matConfValid)
print(matrices_data20$matConfTest)
matrices_data50 = test_dataset(train_50,validation_20,test_50,grid," 50")
matrices_data70 = test_dataset(train_70,validation_20,test_70,grid," 70")
knitr::opts_chunk$set(echo = TRUE)
# Instalar paquetes necesarios si no están descargados todavía
#install.packages(c("rpart", "caret", "pROC", "e1071"))
# Cargar los paquetes
library(rpart)
library(caret)
library(pROC)
library(e1071)
library(ggplot2)
library(corrplot)
library(rpart.plot)
data_original = read.csv('diabetes_dataset.csv')
#Separamos los datos entre los pacientes con diabete y sin diabetes
data_sin = data_original[data_original$diabetes == 0,]
data_con = data_original[data_original$diabetes == 1,]
#contamos la cantidad de pacientes con diabetes
cant_diabetes = nrow(data_original[data_original$diabetes > 0, ])
# Sabemos que la cantidad de gente con diabetes es menor a la cantidad sin diabetes en el dataset, balanceamos esto y hacemos que seaa 50/50 la cantidad de casos con diabetes y sin diabetes (ponemos el seed para reproducibilidad )
set.seed(40)
if(nrow(data_sin) > cant_diabetes) {
data_sin <- data_sin[sample(nrow(data_sin), cant_diabetes, replace = FALSE), ]
}
#juntamos la data y al guardamos
data <- rbind(data_con, data_sin)
# Borramos "loation"
data_sin_location <- subset(data, select = -location)
# Convertir columnas a factores y manejar valores desconocidos
data$gender <- factor(data$gender, levels = c("Male", "Female", "Unknown"))
data$gender[data$gender == "Other"] <- "Unknown"
data$location <- as.factor(data$location)
#data$smoking_history <- as.factor(data$smoking_history)
data$diabetes <- as.factor(data$diabetes)
# Se crea una nueva y única columna para la raza
data$race <- apply(data[, c("race.AfricanAmerican", "race.Asian", "race.Caucasian", "race.Hispanic", "race.Other")], 1, function(row) {
race <- names(which(row == 1))
if (length(race) == 0) return(NA)
return(race)
})
summary(data)
hist(data$age,
main = "Distribución de Edad",
xlab = "Edad",
ylab = "Frecuencia",
col = "skyblue",
border = "white",
breaks = 20,
las = 1,
freq = TRUE)
gender_counts <- table(data$gender)
# Crear un gráfico de barras de la tabla de frecuencias
barplot(gender_counts,
main = "Distribución por Género",
xlab = "Género",
ylab = "Frecuencia",
col = c("lightblue", "lightgreen"),
border = "black",
las = 1,
cex.names = 0.8,
ylim = c(0, max(gender_counts) * 1.2))
data$race <- apply(data[, c("race.AfricanAmerican", "race.Asian", "race.Caucasian", "race.Hispanic", "race.Other")], 1, function(row) {
race <- names(which(row == 1))
if (length(race) == 0) return(NA)  # Manejo de valores NA si ninguna raza está seleccionada
return(race)
})
ggplot(data, aes(x = race, fill = race)) +
geom_bar() +
labs(title = "Distribución de Raza", x = "Raza", y = "Frecuencia") +
theme_minimal()
# Histograma del IMC
ggplot(data, aes(x = bmi)) +
geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
labs(title = "Distribución del IMC", x = "IMC", y = "Frecuencia") +
theme_minimal()
# Boxplot de Edad por Género
ggplot(data, aes(x = gender, y = age, fill = gender)) +
geom_boxplot() +
labs(title = "Distribución de Edad por Género", x = "Género", y = "Edad") +
theme_minimal()
# 1. Filtrar solo las columnas numéricas
data$year <- NULL
df_numeric <- data[, sapply(data, is.numeric)]
# 2. Crear la matriz de correlación
cor_matrix <- cor(df_numeric, use = "complete.obs")
# 3. Visualizar la matriz de correlación con corrplot
corrplot(cor_matrix, method = "color", tl.col = "black", tl.cex = 0.8)
tree_best_features = function(tree){
# Obtener la importancia de las variables
importance <- model$variable.importance
# Ver las importancias
print(importance)
}
#tree_best_features(model)
split_dataset <- function(dataset, train_size = 0.7, validation_size = 0.15, test_size = 0.15, seed = 123) {
# Verificar que los tamaños sumen 1
if (train_size + validation_size + test_size != 1) {
stop("Los tamaños de train, validation y test deben sumar 1")
}
# Configurar la semilla para reproducibilidad, si se proporciona
if (!is.null(seed)) {
set.seed(seed)
}
# Número total de filas en el dataset
num_rows <- nrow(dataset)
# Barajar las filas del dataset
shuffled_indices <- sample(1:num_rows)
# Calcular los tamaños de los conjuntos
train_index <- 1:round(train_size * num_rows)
validation_index <- (length(train_index) + 1):(length(train_index) + round(validation_size * num_rows))
test_index <- (length(validation_index) + length(train_index) + 1):num_rows
# Dividir el dataset en tres subconjuntos
train_set <- dataset[shuffled_indices[train_index], ]
validation_set <- dataset[shuffled_indices[validation_index], ]
test_set <- dataset[shuffled_indices[test_index], ]
# Devolver los subconjuntos en una lista
return(list(train = train_set, validation = validation_set, test = test_set))
}
set = split_dataset(data)
trainData = set$train
validData = set$validation
testData = set$test
default_tree <- rpart(diabetes ~ ., data = trainData , method = "class")
rpart.control()
# Resumen del modelo
print(default_tree)
printcp(default_tree)
plot(default_tree)
text(default_tree, use.n = TRUE, cex = 0.8)
# Clase predicha
predicciones <- predict(default_tree, testData, type = "class")
predicciones <- factor(predicciones)
testData$diabetes <- factor(testData$diabetes)
# Ver las predicciones
#print(predicciones)
# Se crea una matriz de confusión
conf_matrix <- confusionMatrix(predicciones, testData$diabetes)
# Accuracy
accuracy <- conf_matrix$overall["Accuracy"]
print(conf_matrix)
precision <- conf_matrix$byClass["Pos Pred Value"]
recall <- conf_matrix$byClass["Sensitivity"]
print(precision)
print(recall)
# F1-score
f1_score <- 2 * (precision * recall) / (precision + recall)
print(f1_score)
# Probabilidad predicha
predicciones_prob <- predict(default_tree, testData, type = "prob")
probas_positivas = predicciones_prob[,2]
# Calcular el ROC y AUC
roc_curve <- roc(testData$diabetes, probas_positivas, direction = "<")
auc_roc <- auc(roc_curve)
# Mostrar el AUC-ROC
print(auc_roc)
# Graficar la curva ROC
plot(roc_curve, main = "Curva ROC", col = "blue", lwd = 2)
# Agregar la línea diagonal de no discriminación (es decir, el azar)
abline(a = 0, b = 1, lty =2,col="red")
optimizacion <- function(dataset, grid){
# Crear un dataframe para almacenar los resultados de cada combinación
results <- data.frame(
minsplit = numeric(),
minbucket = numeric(),
maxdepth = numeric(),
maxcompete = numeric(),
auc = numeric()
)
# Se inicializan variables para almacenar el mejor modelo y su rendimiento
best_auc <- 0
best_model <- NULL
best_params <- list()
# For para probar todas las combinaciones de hiperparámetros
for (i in 1:nrow(grid)) {
# Extraer los hiperparámetros actuales
params <- grid[i, ]
# Configurar los parámetros de control de rpart
#cp y xval son 0 para poder construir árboles con la máxima profundidad
control <- rpart.control(
cp = 0,
minsplit = params$minsplit,
minbucket = params$minbucket,
maxdepth = params$maxdepth,
xval = 0
)
# Se entrena al modelo usando rpart con los hiperparámetros actuales
model <- rpart(diabetes ~ ., data = trainData, method = "class", control = control)
# Se predecir en el conjunto de validación y calcular AUC-ROC
train_pred <- predict(model, newdata = trainData, type = "prob")[,2]
auc_valid <- auc(roc(trainData$diabetes, train_pred))
# Guardar los resultados en el dataframe
results <- rbind(results, data.frame(
minsplit = params$minsplit,
minbucket = params$minbucket,
maxdepth = params$maxdepth,
maxcompete = params$maxcompete,
auc = auc_valid
))
# Actualizar el mejor modelo si el actual es mejor
if (auc_valid > best_auc) {
best_auc <- auc_valid
best_model <- model
best_params <- params
}
# Se imprime el progreso
#cat(i, "/", nrow(grid), "- AUC-ROC:", auc_valid, "\n")
}
return (list(AUC = best_auc, model = best_model, hyperParameters= best_params, allResults = results))
}
# Se crea una combinación de todos los hiperparámetros
grid <- expand.grid(
minsplit = c(10, 20, 30, 50),
minbucket = c(5, 10, 15, 20),
maxdepth = c(2, 5, 10, 15, 20, 25),
maxcompete = c(1, 3, 5, 10)
)
modelo_optimizado = optimizacion(data, grid)
best_auc = modelo_optimizado$AUC
best_model = modelo_optimizado$model
best_params = modelo_optimizado$hyperParameters
results = modelo_optimizado$allResults
# La mejor AUC-ROC e hiperparámetros optimizados del modelo son:
cat("Mejor AUC-ROC:", best_auc, "\n")
cat("Mejores Hiperparámeteros:", "\n")
print(best_params)
# Gráfico de calor para visualizar la relación entre maxdepth y minsplit con AUC-ROC
ggplot(results, aes(x = factor(maxdepth), y = factor(minsplit), fill = auc)) +
geom_tile() +
scale_fill_gradient(low = "blue", high = "red") +
labs(title = "Relación entre Maxdepth, Minsplit y AUC-ROC",
x = "Maxdepth",
y = "Minsplit") +
theme_minimal()
# Gráfico de calor para visualizar la relación entre maxcompete y maxdepth con AUC-ROC
ggplot(results, aes(x = factor(maxcompete), y = factor(maxdepth), fill = auc)) +
geom_tile() +
scale_fill_gradient(low = "yellow", high = "purple") +
labs(title = "Relación entre Maxcompete, Maxdepth y AUC-ROC",
x = "Maxcompete",
y = "Maxdepth") +
theme_minimal()
# Gráfico de líneas para observar cómo varía el AUC-ROC con diferentes combinaciones de hiperparámetros
ggplot(results, aes(x = maxdepth, y = auc, color = factor(minsplit))) +
geom_line() +
geom_point() +
labs(title = "AUC-ROC vs Maxdepth para diferentes Minsplit",
x = "Maxdepth",
y = "AUC-ROC",
color = "Minsplit") +
theme_minimal()
rendimiento_modelo <- function(data, modelo, nombre_grafico){
prediccion <- predict(modelo, newdata = data, type = "prob")[,2]
roc_test <- roc(data$diabetes, prediccion)
auc_test <- auc(roc_test)
cat("AUC-ROC on test set:", auc_test, "\n")
## Visualización de la curva AUC-ROC
# Se grafica la curva ROC
plot(roc_test, col = "blue", lwd = 2, main = paste("Curva AUC-ROC ",nombre_grafico), auc.polygon = TRUE, grid = TRUE)
# Se añade la línea diagonal
abline(a = 0, b = 1, col = "gray", lty = 2)
# Convertir 'predicciones' a factor con los mismos niveles que 'testData$diabetes'
prediccion <- as.factor(prediccion)
##macheamos a factores
prediccion <- factor(prediccion, levels = levels(data$diabetes))
# Crear una tabla de confusión
conf_matrix <- confusionMatrix(prediccion, data$diabetes)
# Accuracy
accuracy <- conf_matrix$overall["Accuracy"]
return (list(matConfusion = conf_matrix, accuracy = accuracy))
}
#Validacion
rendimiento_validacion = rendimiento_modelo(validData,best_model,"(Validacion)")
matriz_confusion_validacion = rendimiento_validacion$matConfusion
print(matriz_confusion_validacion)
#Testeo
rendimiento_testeo = rendimiento_modelo(testData,best_model, "(Testeo)")
matriz_confusion_testeo = rendimiento_testeo$matConfusion
print(matriz_confusion_testeo)
#cex controla el tamaño del texto en el gráfico.
#tweak ajusta el tamaño de la gráfica en general.
#rpart.plot(model, type = 3, extra = 104, fallen.leaves = TRUE, cex = 0.8, tweak = 1.2)
# Función que introduce NA
dataset_NAgenerator <- function(dataset, rate) {
# Verificar que el rate esté entre 1 y 100
if (rate < 1 | rate > 100) {
stop("El 'rate' debe estar entre 1 y 100")
}
# Se hace una copia del dataset para no modificar el original
dataset_na <- dataset
# Se convierte el rate a un porcentaje
rate <- rate / 100
# El número de filas en el dataset
num_rows <- nrow(dataset_na)
# El número de filas a reemplazar por NA para la columna actual
num_na <- round(num_rows * rate)
# Se iterar sobre cada columna
for (col in colnames(dataset_na)) {
# Se saltea la columna 'diabetes'
if (col != 'diabetes') {
# Se seleccionan filas aleatorias para reemplazar por NA en la columna actual
rows_to_na <- sample(1:num_rows, num_na)
# Se reemplaza las filas seleccionadas por NA en la columna actual
dataset_na[rows_to_na, col] <- NA
}
}
return(dataset_na)
}
set_20 = split_dataset(data)
train_20 = set_20$train
train_20 = dataset_NAgenerator(train_20,20)
validation_20 = set_20$validation
validation_20 = dataset_NAgenerator(validation_20,20)
test_20 = set_20$test
test_20 = dataset_NAgenerator(test_20,20)
set_50 = split_dataset(data)
train_50 = set_50$train
train_50 = dataset_NAgenerator(train_50,50)
validation_50 = set_50$validation
validation_50 = dataset_NAgenerator(validation_50,50)
test_50 = set_50$test
test_50 = dataset_NAgenerator(test_50,50)
set_70 = split_dataset(data)
train_70 = set_70$train
train_70 = dataset_NAgenerator(train_70,70)
validation_70 = set_70$validation
validation_70 = dataset_NAgenerator(validation_70,70)
test_70 = set_70$test
test_70 = dataset_NAgenerator(test_70,70)
#Esto es todo lo que deberiamos hacer oara cad auno de los data sets
test_dataset = function(train,valid,test,grid,porcentaje){
modelo_optimizado = optimizacion(train, grid)
best_auc = modelo_optimizado$AUC
best_model = modelo_optimizado$model
best_params = modelo_optimizado$hyperParameters
results = modelo_optimizado$allResults
#Validacion
rendimiento_validacion = rendimiento_modelo(valid,best_model,paste("- Validación (NAs ", porcentaje,"%)"))
matriz_confusion_validacion = rendimiento_validacion$matConfusion
#print(matriz_confusion_validacion) paste("- Validación (NAs ", porcentaje,"%)")
#Testeo
rendimiento_testeo = rendimiento_modelo(test,best_model, paste("- Test (NAs ", porcentaje,"%)"))
matriz_confusion_testeo = rendimiento_testeo$matConfusion
#print(matriz_confusion_testeo)
return (list(matConfValid = matriz_confusion_validacion,matConfTest = matriz_confusion_testeo))
}
matrices_data20 = test_dataset(train_20,validation_20,test_20,grid," 20")
print(matrices_data20$matConfValid)
print(matrices_data20$matConfTest)
matrices_data50 = test_dataset(train_50,validation_20,test_50,grid," 50")
matrices_data70 = test_dataset(train_70,validation_20,test_70,grid," 70")
# Creación del dataframe con las métricas de cada matriz de confusión
df_metricas <- data.frame(
Porcentaje_Faltantes = c("0% (original)", "20%", "50%", "70%"),
Accuracy = c(0.9634, 0.942, 0.9179, 0.8655),
Sensitivity = c(0.9557, 0.9359, 0.8953, 0.7954),
Specificity = c(0.9702, 0.9473, 0.9365, 0.9286),
Kappa = c(0.9265, 0.8835, 0.8339, 0.7285)
)
print(df_metricas)
# Convertir el dataframe a formato largo para ggplot2
df_metricas_largo <- melt(df_metricas, id.vars = "Porcentaje_Faltantes")
# Gráfico de barras
ggplot(df_metricas_largo, aes(x = Porcentaje_Faltantes, y = value, fill = variable)) +
geom_bar(stat = "identity", position = position_dodge()) +
labs(title = "Comparación de Métricas de Evaluación según el Porcentaje de Datos Faltantes",
x = "Porcentaje de Datos Faltantes",
y = "Valor de la Métrica",
fill = "Métrica") +
theme_minimal()
# Gráfico de líneas
ggplot(df_metricas_largo, aes(x = Porcentaje_Faltantes, y = value, color = variable, group = variable)) +
geom_line(size = 1) +
geom_point(size = 3) +
labs(title = "Tendencia de las Métricas de Evaluación según el Porcentaje de Datos Faltantes",
x = "Porcentaje de Datos Faltantes",
y = "Valor de la Métrica",
color = "Métrica") +
theme_minimal()
tree_best_features = function(tree){
# Obtener la importancia de las variables
importance <- model$variable.importance
# Ver las importancias
print(importance)
}
tree_best_features(default_tree)
tree_best_features = function(tree){
# Obtener la importancia de las variables
importance <- model$variable.importance
# Ver las importancias
print(importance)
}
tree_best_features(model)
tree_best_features = function(tree){
# Obtener la importancia de las variables
importance <- model$variable.importance
# Ver las importancias
print(importance)
}
tree_best_features(best_model)
tree_best_features = function(tree){
# Obtener la importancia de las variables
importance <- tree$variable.importance
# Ver las importancias
print(importance)
}
tree_best_features(best_model)
tree_best_features = function(tree){
# Obtener la importancia de las variables
importance <- tree$variable.importance
# Ver las importancias
print(importance)
}
tree_best_features(model)
tree_best_features = function(tree){
# Obtener la importancia de las variables
importance <- tree$variable.importance
# Ver las importancias
print(importance)
}
tree_best_features(default_tree)
knitr::opts_chunk$set(echo = TRUE)
# Instalar paquetes necesarios si no están descargados todavía
#install.packages(c("rpart", "caret", "pROC", "e1071", "ggplot2","corrplot","rpart.plot", "reshape2","reshape","htmltools","widgetframe"))
# Cargar los paquetes
library(rpart)
library(caret)
library(pROC)
library(e1071)
library(ggplot2)
library(corrplot)
library(rpart.plot)
library(reshape2)
library(reshape)
